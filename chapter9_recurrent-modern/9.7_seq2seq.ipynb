{
 "cells": [
  {
   "cell_type": "code",
   "id": "bc9aa4b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:31.967521Z",
     "iopub.status.busy": "2023-08-18T07:15:31.966534Z",
     "iopub.status.idle": "2023-08-18T07:15:33.959337Z",
     "shell.execute_reply": "2023-08-18T07:15:33.958486Z"
    },
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2025-04-09T02:12:46.688065Z",
     "start_time": "2025-04-09T02:12:46.682880Z"
    }
   },
   "source": [
    "import collections\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:33.963601Z",
     "iopub.status.busy": "2023-08-18T07:15:33.962917Z",
     "iopub.status.idle": "2023-08-18T07:15:33.969272Z",
     "shell.execute_reply": "2023-08-18T07:15:33.968489Z"
    },
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2025-04-09T02:12:48.124732Z",
     "start_time": "2025-04-09T02:12:48.117015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#用于序列到序列学习的循环神经网络编码器\n",
    "class Seq2SeqEncoder(d2l.Encoder):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, **kwargs):\n",
    "        super(Seq2SeqEncoder, self).__init__(**kwargs)\n",
    "        # 嵌入层\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers,\n",
    "                          dropout=dropout)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        # 将词索引映射成嵌入向量\n",
    "        X = self.embedding(X)\n",
    "        # 调整输出向量的维度\n",
    "        X = X.permute(1, 0, 2)\n",
    "        output, state = self.rnn(X)\n",
    "        return output, state"
   ],
   "id": "3dbfb3ed",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T02:12:49.459662Z",
     "start_time": "2025-04-09T02:12:49.447611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# permute的用法 用于调整向量的维度\n",
    "import torch\n",
    "\n",
    "# 假设有一个形状为 (2, 3, 4) 的张量\n",
    "temp = torch.randn(2, 3, 4)\n",
    "print(\"原始张量的形状:\", temp.shape)\n",
    "\n",
    "# 使用 permute 重新排列维度\n",
    "temp_permuted = temp.permute(1, 0, 2)\n",
    "# 重新排列维度后的形状: torch.Size([3, 2, 4])\n",
    "print(\"重新排列维度后的形状:\", temp_permuted.shape)\n",
    "\n",
    "# 打印原始张量和重新排列后的张量\n",
    "print(\"原始张量:\\n\", temp)\n",
    "print(\"重新排列后的张量:\\n\", temp_permuted)"
   ],
   "id": "cdf234596f6b713",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始张量的形状: torch.Size([2, 3, 4])\n",
      "重新排列维度后的形状: torch.Size([3, 2, 4])\n",
      "原始张量:\n",
      " tensor([[[-0.2167, -0.7214, -1.1619,  0.7126],\n",
      "         [ 0.7325, -0.1458, -0.5945, -1.1517],\n",
      "         [ 0.4763,  1.1110,  0.4661,  1.6304]],\n",
      "\n",
      "        [[ 0.4059, -1.0617,  0.1535, -1.8772],\n",
      "         [ 0.4663,  0.7954,  0.9865, -0.4461],\n",
      "         [-0.0192, -0.1635, -0.1410,  1.0554]]])\n",
      "重新排列后的张量:\n",
      " tensor([[[-0.2167, -0.7214, -1.1619,  0.7126],\n",
      "         [ 0.4059, -1.0617,  0.1535, -1.8772]],\n",
      "\n",
      "        [[ 0.7325, -0.1458, -0.5945, -1.1517],\n",
      "         [ 0.4663,  0.7954,  0.9865, -0.4461]],\n",
      "\n",
      "        [[ 0.4763,  1.1110,  0.4661,  1.6304],\n",
      "         [-0.0192, -0.1635, -0.1410,  1.0554]]])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "1780ca82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:33.972667Z",
     "iopub.status.busy": "2023-08-18T07:15:33.972142Z",
     "iopub.status.idle": "2023-08-18T07:15:34.003637Z",
     "shell.execute_reply": "2023-08-18T07:15:34.002907Z"
    },
    "origin_pos": 12,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2025-04-09T02:12:51.310674Z",
     "start_time": "2025-04-09T02:12:51.292343Z"
    }
   },
   "source": [
    "encoder = Seq2SeqEncoder(vocab_size=10, embed_size=8, num_hiddens=16,\n",
    "                         num_layers=2)\n",
    "# eval()用于将模型设置为评估模式\n",
    "encoder.eval()\n",
    "# batch_size = 4, num_steps = 7\n",
    "X = torch.zeros((4, 7), dtype=torch.long)\n",
    "output, state = encoder(X)\n",
    "# output的形状:(num_steps,batch_size,num_hiddens)\n",
    "output.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 4, 16])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "32a2c1d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:34.007123Z",
     "iopub.status.busy": "2023-08-18T07:15:34.006595Z",
     "iopub.status.idle": "2023-08-18T07:15:34.011456Z",
     "shell.execute_reply": "2023-08-18T07:15:34.010716Z"
    },
    "origin_pos": 17,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2025-04-09T02:12:53.141915Z",
     "start_time": "2025-04-09T02:12:53.134298Z"
    }
   },
   "source": [
    "# state的形状:(num_layers,batch_size,num_hiddens)\n",
    "state.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 16])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 编码器的前向传播计算\n",
    "\n",
    "---\n",
    "\n",
    "## 初始输入\n",
    "\n",
    "```python\n",
    "X = torch.zeros((4, 7), dtype=torch.long)\n",
    "```\n",
    "\n",
    "- **形状**: `(batch_size, num_steps)` = `(4, 7)`\n",
    "  - `batch_size=4`: 输入批次中的样本数为 4。\n",
    "  - `num_steps=7`: 每个序列的时间步数（词的个数）为 7。\n",
    "\n",
    "---\n",
    "\n",
    "## 1. 嵌入层 (`self.embedding`)\n",
    "\n",
    "嵌入层的作用是将每个词索引映射为对应的嵌入向量。嵌入层的权重矩阵（通常称为嵌入矩阵）大小为 `(vocab_size, embed_size)`，其中：\n",
    "- `vocab_size=10`: 词汇表的大小，表示可用的词索引范围是 `[0, 9]`。\n",
    "- `embed_size=8`: 每个词将被表示为 8 维的向量。\n",
    "\n",
    "嵌入层的计算过程如下：\n",
    "1. **输入数据**:\n",
    "   - 输入张量 `X` 的形状是 `(batch_size, num_steps)` = `(4, 7)`。\n",
    "   - 张量中的每个值是一个整数，表示词汇表中的索引。例如：\n",
    "     ```python\n",
    "     X = [[0, 1, 2, 3, 4, 5, 6],\n",
    "          [7, 8, 9, 0, 1, 2, 3],\n",
    "          [4, 5, 6, 7, 8, 9, 0],\n",
    "          [1, 2, 3, 4, 5, 6, 7]]\n",
    "     ```\n",
    "\n",
    "2. **嵌入矩阵查找**:\n",
    "   - 对于每个词索引（例如 `0`, `1`, `2` 等），嵌入层会从嵌入矩阵中查找对应的嵌入向量。\n",
    "   - 嵌入矩阵的形状为 `(vocab_size, embed_size)` = `(10, 8)`：\n",
    "     ```python\n",
    "     embedding_matrix = [\n",
    "         [0.2, 0.1, -0.3, ..., 0.8],  # 嵌入向量 for 索引 0\n",
    "         [0.5, -0.6, 0.7, ..., -0.1], # 嵌入向量 for 索引 1\n",
    "         ...\n",
    "         [-0.3, 0.4, 0.1, ..., 0.6],  # 嵌入向量 for 索引 9\n",
    "     ]\n",
    "     ```\n",
    "   - 每个索引值会被映射到嵌入矩阵中的一行。例如：\n",
    "     - 索引 `0` → `[0.2, 0.1, -0.3, ..., 0.8]` (8 维向量)\n",
    "     - 索引 `1` → `[0.5, -0.6, 0.7, ..., -0.1]` (8 维向量)\n",
    "\n",
    "3. **输出张量**:\n",
    "   - 嵌入层为每个时间步的词索引生成一个嵌入向量。\n",
    "   - 输入形状 `(batch_size, num_steps)` = `(4, 7)` 转换为：\n",
    "     **`(batch_size, num_steps, embed_size)`** = `(4, 7, 8)`。\n",
    "---\n",
    "## 2. 维度调整 (`permute`)\n",
    "\n",
    "**计算原理**:\n",
    "为了适配循环神经网络（RNN）的输入格式，需要将时间步数（`num_steps`）调整到张量的第一维。\n",
    "PyTorch 的 RNN 模块要求输入的形状为 `(num_steps, batch_size, embed_size)`。\n",
    "\n",
    "```python\n",
    "X = X.permute(1, 0, 2)\n",
    "```\n",
    "\n",
    "- **输入形状**: `(batch_size, num_steps, embed_size)` = `(4, 7, 8)`\n",
    "- **输出形状**: `(num_steps, batch_size, embed_size)` = `(7, 4, 8)`\n",
    "  - `num_steps=7`: 序列的长度（时间步数）。\n",
    "  - `batch_size=4`: 批量大小。\n",
    "  - `embed_size=8`: 嵌入向量的维度。\n",
    "\n",
    "---\n",
    "\n",
    "## 3. GRU 编码器 (`self.rnn`)\n",
    "\n",
    "**计算原理**:\n",
    "GRU 是一种循环神经网络（RNN），接受一个形状为 `(num_steps, batch_size, embed_size)` 的输入张量，计算每个时间步的隐藏状态，并输出：\n",
    "1. 每个时间步的隐藏状态序列（`output`）。\n",
    "2. 最终的隐藏状态（`state`）。\n",
    "\n",
    "GRU 的输入向量维度为 `embed_size=8`，隐藏层状态的维度为 `num_hiddens=16`，网络有 `num_layers=2` 层。\n",
    "\n",
    "```python\n",
    "output, state = self.rnn(X)\n",
    "```\n",
    "\n",
    "- **输入形状**: `(num_steps, batch_size, embed_size)` = `(7, 4, 8)`\n",
    "- **输出结果**:\n",
    "  1. **`output`**: 每个时间步的隐藏状态序列。\n",
    "     - **形状**: `(num_steps, batch_size, num_hiddens)` = `(7, 4, 16)`\n",
    "       - `num_steps=7`: 序列的长度（时间步数）。\n",
    "       - `batch_size=4`: 批量大小。\n",
    "       - `num_hiddens=16`: GRU 的隐藏状态维度。\n",
    "  2. **`state`**: 最终的隐藏状态。\n",
    "     - **形状**: `(num_layers, batch_size, num_hiddens)` = `(2, 4, 16)`\n",
    "       - `num_layers=2`: GRU 的层数。\n",
    "       - `batch_size=4`: 批量大小。\n",
    "       - `num_hiddens=16`: GRU 的隐藏状态维度。\n",
    "\n"
   ],
   "id": "f2ce4fcbe5f2d81d"
  },
  {
   "cell_type": "code",
   "id": "09143bb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:34.014841Z",
     "iopub.status.busy": "2023-08-18T07:15:34.014327Z",
     "iopub.status.idle": "2023-08-18T07:15:34.021372Z",
     "shell.execute_reply": "2023-08-18T07:15:34.020591Z"
    },
    "origin_pos": 21,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2025-04-09T02:13:10.755324Z",
     "start_time": "2025-04-09T02:13:10.747591Z"
    }
   },
   "source": [
    "# 解码器\n",
    "class Seq2SeqDecoder(d2l.Decoder):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, **kwargs):\n",
    "        super(Seq2SeqDecoder, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size + num_hiddens, num_hiddens, num_layers,dropout=dropout)\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, *args):\n",
    "        return enc_outputs[1]\n",
    "\n",
    "    # 解码器的输入就是编码器的输出\n",
    "    # X是一开始输入的变量(4,7) state(2,4,16)\n",
    "    def forward(self, X, state):\n",
    "        # 嵌入层 X(4,7)->(7,4,8)\n",
    "        X = self.embedding(X).permute(1, 0, 2)\n",
    "        # 从隐状态中提取信息，并将其与嵌入向量进行\n",
    "        context = state[-1].repeat(X.shape[0], 1, 1)\n",
    "        X_and_context = torch.cat((X, context), 2)\n",
    "        output, state = self.rnn(X_and_context, state)\n",
    "        output = self.dense(output).permute(1, 0, 2)\n",
    "        return output, state"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "ad17a24d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:34.024844Z",
     "iopub.status.busy": "2023-08-18T07:15:34.024212Z",
     "iopub.status.idle": "2023-08-18T07:15:34.034277Z",
     "shell.execute_reply": "2023-08-18T07:15:34.033517Z"
    },
    "origin_pos": 26,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2025-04-09T02:13:14.242075Z",
     "start_time": "2025-04-09T02:13:14.228117Z"
    }
   },
   "source": [
    "decoder = Seq2SeqDecoder(vocab_size=10, embed_size=8, num_hiddens=16,\n",
    "                         num_layers=2)\n",
    "decoder.eval()\n",
    "# encoder(X) 返回两个内容 一个是上下文变量c 一个是隐状态state\n",
    "state = decoder.init_state(encoder(X))\n",
    "output, state = decoder(X, state)\n",
    "# output的形状为\n",
    "output.shape, state.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 7, 10]), torch.Size([2, 4, 16]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 解码器的前向传播计算\n",
    "## 1. 编码器输出\n",
    "\n",
    "假设编码器的输出为：\n",
    "- **`enc_outputs`**:\n",
    "  - `enc_outputs[0]` (编码器的输出序列): `(num_steps_enc, batch_size, num_hiddens)` = `(7, 4, 16)`\n",
    "  - `enc_outputs[1]` (编码器的隐藏状态): `(num_layers, batch_size, num_hiddens)` = `(2, 4, 16)`\n",
    "\n",
    "在解码器中，编码器的隐藏状态 `enc_outputs[1]` 被用作解码器的初始状态。\n",
    "\n",
    "---\n",
    "\n",
    "## 2. 解码器输入\n",
    "\n",
    "解码器的输入由两部分组成：\n",
    "1. 目标序列的词索引 `X`：\n",
    "   - 假设目标序列的形状为 `(batch_size, num_steps_dec)` = `(4, 7)`。\n",
    "   - 其中，`batch_size=4` 表示批量大小，`num_steps_dec=7` 表示目标序列的时间步数。\n",
    "\n",
    "2. 编码器的隐藏状态 `state`：\n",
    "   - 由 `enc_outputs[1]` 初始化，形状为 `(num_layers, batch_size, num_hiddens)` = `(2, 4, 16)`。\n",
    "\n",
    "---\n",
    "\n",
    "## 3. 嵌入层 (`self.embedding`)\n",
    "\n",
    "**计算原理**:\n",
    "嵌入层将目标序列的词索引映射为对应的嵌入向量。嵌入层的权重矩阵大小为 `(vocab_size, embed_size)`，其中：\n",
    "- `vocab_size=10`: 目标词汇表大小。\n",
    "- `embed_size=8`: 每个词被映射为 8 维的嵌入向量。\n",
    "\n",
    "**计算过程**:\n",
    "1. 输入 `X` 的形状为 `(batch_size, num_steps_dec)` = `(4, 7)`。\n",
    "2. 嵌入层将其映射为 `(batch_size, num_steps_dec, embed_size)` = `(4, 7, 8)`。\n",
    "3. 调整维度顺序 `.permute(1, 0, 2)`，输出形状为 `(num_steps_dec, batch_size, embed_size)` = `(7, 4, 8)`。\n",
    "\n",
    "---\n",
    "\n",
    "## 4. 广播上下文\n",
    "\n",
    "**计算原理**:\n",
    "解码器需要从编码器传递的隐藏状态中提取上下文信息，并将其与目标序列的嵌入向量结合。\n",
    "\n",
    "**计算过程**:\n",
    "1. state[-1]: 获取编码器最后一层隐藏状态，形状为 (batch_size, num_hiddens)。\n",
    "state 的形状是 (2, 4, 16)，那么 state[-1] 的形状为 (4, 16)。\n",
    "\n",
    "2. .repeat(X.shape[0], 1, 1):\n",
    "X.shape[0] 是解码器的时间步数（num_steps），这里为 7。\n",
    ".repeat 的作用是扩展 state[-1] 的形状：\n",
    "在第 0 维（时间步数）上重复 7 次。\n",
    "在第 1 维（批量大小）和第 2 维（隐藏状态维度）上保持不变。\n",
    "\n",
    "3. 输出 context:\n",
    "广播后的 context 的形状为 (num_steps, batch_size, num_hiddens)。\n",
    "假设 state[-1] 的形状是 (4, 16)，广播后 context 的形状为 (7, 4, 16)\n",
    "---\n",
    "\n",
    "## 5. 拼接输入与上下文\n",
    "\n",
    "**计算原理**:\n",
    "将目标序列的嵌入向量与广播后的上下文在最后一个维度上拼接，以便 GRU 同时处理目标序列输入和上下文信息。\n",
    "\n",
    "**计算过程**:\n",
    "1. 嵌入层输出 `X` 的形状为 `(num_steps_dec, batch_size, embed_size)` = `(7, 4, 8)`。\n",
    "2. 广播后的上下文 `context` 的形状为 `(num_steps_dec, batch_size, num_hiddens)` = `(7, 4, 16)`。\n",
    "3. 拼接后，`X_and_context` 的形状为 `(num_steps_dec, batch_size, embed_size + num_hiddens)` = `(7, 4, 24)`。\n",
    "\n",
    "---\n",
    "\n",
    "## 6. GRU 层 (`self.rnn`)\n",
    "\n",
    "**计算原理**:\n",
    "GRU 接收拼接后的输入 `X_and_context` 和初始隐藏状态 `state`，逐步计算每个时间步的隐藏状态和最终输出。\n",
    "\n",
    "**计算过程**:\n",
    "1. 输入 `X_and_context` 的形状为 `(num_steps_dec, batch_size, embed_size + num_hiddens)` = `(7, 4, 24)`。\n",
    "2. 初始隐藏状态 `state` 的形状为 `(num_layers, batch_size, num_hiddens)` = `(2, 4, 16)`。\n",
    "3. GRU 的输出：\n",
    "   - 每个时间步的隐藏状态序列 `output` 的形状为 `(num_steps_dec, batch_size, num_hiddens)` = `(7, 4, 16)`。\n",
    "   - 最终隐藏状态 `state` 的形状为 `(num_layers, batch_size, num_hiddens)` = `(2, 4, 16)`。\n",
    "\n",
    "---\n",
    "\n",
    "## 7. 全连接层 (`self.dense`)\n",
    "\n",
    "**计算原理**:\n",
    "全连接层将 GRU 输出的隐藏状态映射到词汇表维度，用于预测目标序列中的词分布。\n",
    "\n",
    "**计算过程**:\n",
    "1. 全连接层的输入： 输入 output 的形状为 (num_steps_dec, batch_size, num_hiddens) = (7, 4, 16)。\n",
    "2. 全连接层的权重和偏置： 权重矩阵的形状为 (num_hiddens, vocab_size) = (16, 10)。 偏置向量的形状为 (vocab_size,) = (10,)。\n",
    "3. 全连接层的输出：映射后的形状为 (num_steps_dec, batch_size, vocab_size) = (7, 4, 10)。\n",
    "4. 调整维度顺序 .permute(1, 0, 2)：将形状从 (num_steps_dec, batch_size, vocab_size) = (7, 4, 10) 调整为 (batch_size, num_steps_dec, vocab_size) = (4, 7, 10)。\n",
    "\n",
    ""
   ],
   "id": "929d7cd438a9eeb4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 从编码器输入到解码器输出的过程\n",
    "#### **编码器部分**\n",
    "\n",
    "1. **输入数据准备**\n",
    "   源序列的词索引被提供给编码器。词索引是每个单词的唯一标识，用于表示输入序列。\n",
    "\n",
    "2. **嵌入层处理**\n",
    "   编码器通过嵌入层将词索引转换为嵌入向量。这些嵌入向量是稠密的表示形式，捕获了每个单词的语义信息。\n",
    "\n",
    "3. **GRU 层处理**\n",
    "   嵌入向量被输入到 GRU 层，编码器通过多层 GRU 提取序列的时间依赖关系和全局语义信息。\n",
    "   GRU 的输出包括：\n",
    "   - 每个时间步的隐藏状态序列。\n",
    "   - 最终的隐藏状态。\n",
    "\n",
    "4. **返回编码器结果**\n",
    "   编码器的输出（上下文变量和隐藏状态）被传递给解码器，用于引导解码过程。\n",
    "\n",
    "---\n",
    "\n",
    "#### **解码器部分**\n",
    "\n",
    "1. **初始化解码器状态**\n",
    "   解码器从编码器接收最终隐藏状态，作为解码器的初始状态，同时准备目标序列的词索引作为输入。\n",
    "\n",
    "2. **目标序列嵌入**\n",
    "   解码器通过嵌入层将目标序列的词索引转换为嵌入向量，这些向量表示目标序列的语义信息。\n",
    "\n",
    "3. **广播上下文**\n",
    "   编码器的上下文信息（最后一层隐藏状态）被广播到目标序列的每个时间步，确保解码器的每个时间步都能访问全局上下文信息。\n",
    "\n",
    "4. **拼接输入与上下文**\n",
    "   解码器将目标序列的嵌入向量与广播的上下文信息拼接在一起，作为解码器的输入。\n",
    "\n",
    "5. **GRU 层处理**\n",
    "   拼接后的输入被送入解码器的 GRU 层，逐步生成目标序列的隐藏状态序列，并更新内部隐藏状态。\n",
    "\n",
    "6. **全连接层映射**\n",
    "   解码器通过全连接层将 GRU 的隐藏状态映射到目标词汇表分布，用于预测目标序列中的每个词。\n",
    "\n",
    "7. **输出调整**\n",
    "   解码器调整输出的形状，使其符合目标序列的格式，生成最终的词分布，用于目标序列的预测。\n",
    "\n",
    "---\n",
    "\n",
    "#### **最终结果**\n",
    "\n",
    "1. **输出分布**\n",
    "   包含目标序列每个时间步的词分布，用于生成具体的目标词。\n",
    "\n",
    "2. **最终隐藏状态**\n",
    "   包含解码器的最终隐藏状态，可用于进一步的解码或其他操作。\n"
   ],
   "id": "8e6b4e48e97f62f"
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:34.037911Z",
     "iopub.status.busy": "2023-08-18T07:15:34.037256Z",
     "iopub.status.idle": "2023-08-18T07:15:34.044866Z",
     "shell.execute_reply": "2023-08-18T07:15:34.044120Z"
    },
    "origin_pos": 31,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2025-04-09T02:35:05.868797Z",
     "start_time": "2025-04-09T02:35:05.858387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 损失函数部分\n",
    "# 在数据集处理的过程中 通过在序列末尾填充特定的词元保持序列长度的相同\n",
    "# 使用该函数通过零值化屏蔽不相关的项\n",
    "def sequence_mask(X, valid_len, value=0):\n",
    "    # 获取x的列数\n",
    "    maxlen = X.size(1)\n",
    "    # mask是一个二维数组\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                        device=X.device)[None, :] < valid_len[:, None]\n",
    "    X[~mask] = value\n",
    "    return X\n",
    "# X 是一个二维张量，表示序列数据\n",
    "# valid_len 是一个一维张量，表示每个序列需要保留的有效长度。\n",
    "X = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "sequence_mask(X, torch.tensor([1, 2]))\n",
    "# maxlen = 3\n",
    "# mask = tensor([[ True, False, False],\n",
    "#        [ True,  True, False]])"
   ],
   "id": "57c5a5f4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [4, 5, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                        device=X.device)[None, :] < valid_len[:, None]\n",
    "\n",
    "1. **`[None, :]`**\n",
    "   - 给张量新增一个维度，形状从 `(maxlen,)` 变为 `(1, maxlen)`。\n",
    "   - 示例:\n",
    "     ```\n",
    "     tensor([[0., 1., 2.]])\n",
    "     ```\n",
    "2. **`valid_len[:, None]`**\n",
    "   - 将 `valid_len` 转换为二维张量，形状从 `(batch_size,)` 变为 `(batch_size, 1)`。\n",
    "   - 示例（当 `valid_len = [1, 2]`）:\n",
    "     ```\n",
    "     tensor([[1.],\n",
    "             [2.]])\n",
    "     ```\n",
    "\n",
    "3. **布尔掩码生成**\n",
    "   - 利用 `<` 操作生成布尔掩码，表示哪些位置是有效的。\n",
    "   - PyTorch 广播机制会将 `(1, maxlen)` 和 `(batch_size, 1)` 扩展为 `(batch_size, maxlen)`。\n",
    "   - 示例：\n",
    "     ```\n",
    "     mask = [[True, False, False],\n",
    "             [True, True, False]]\n",
    "     ```"
   ],
   "id": "7d8b7f9aab788eec"
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:34.048373Z",
     "iopub.status.busy": "2023-08-18T07:15:34.047745Z",
     "iopub.status.idle": "2023-08-18T07:15:34.054283Z",
     "shell.execute_reply": "2023-08-18T07:15:34.053539Z"
    },
    "origin_pos": 36,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2025-04-09T02:39:47.695702Z",
     "start_time": "2025-04-09T02:39:47.686300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 按照个人需求 可以使用指定非零值替代这些项\n",
    "X = torch.ones(2, 3, 4)\n",
    "sequence_mask(X, torch.tensor([1, 2]), value=-1)"
   ],
   "id": "fbb003c2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  1.,  1.,  1.],\n",
       "         [-1., -1., -1., -1.],\n",
       "         [-1., -1., -1., -1.]],\n",
       "\n",
       "        [[ 1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.],\n",
       "         [-1., -1., -1., -1.]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:34.057946Z",
     "iopub.status.busy": "2023-08-18T07:15:34.057267Z",
     "iopub.status.idle": "2023-08-18T07:15:34.062428Z",
     "shell.execute_reply": "2023-08-18T07:15:34.061664Z"
    },
    "origin_pos": 41,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2025-04-09T02:42:40.624784Z",
     "start_time": "2025-04-09T02:42:40.617646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 对交叉熵损失函数进行拓展\n",
    "# 继承自 PyTorch 的 nn.CrossEntropyLoss\n",
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    \"\"\"带遮蔽的softmax交叉熵损失函数\"\"\"\n",
    "    # 模型预测输出pred的形状：(batch_size,num_steps,vocab_size)\n",
    "    # 目标标签label的形状：(batch_size,num_steps)\n",
    "    # 序列有效长度valid_len的形状：(batch_size,)\n",
    "    def forward(self, pred, label, valid_len):\n",
    "        # 创建一个与 label 形状相同的张量，所有元素初始化为 1\n",
    "        weights = torch.ones_like(label)\n",
    "        # 进行遮蔽\n",
    "        weights = sequence_mask(weights, valid_len)\n",
    "        # 不对批量数据的损失进行任何聚合（如求和或取平均），而是保留每个样本的逐元素损失。\n",
    "        self.reduction='none'\n",
    "        # 未加权损失\n",
    "        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(\n",
    "            pred.permute(0, 2, 1), label)\n",
    "        # 加权损失(遮蔽后的权重相乘)\n",
    "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
    "        return weighted_loss"
   ],
   "id": "0da33ae4",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:34.065956Z",
     "iopub.status.busy": "2023-08-18T07:15:34.065339Z",
     "iopub.status.idle": "2023-08-18T07:15:34.073758Z",
     "shell.execute_reply": "2023-08-18T07:15:34.072755Z"
    },
    "origin_pos": 46,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2025-04-09T02:50:00.140300Z",
     "start_time": "2025-04-09T02:50:00.130796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 代码及安全性检查\n",
    "# 输出结果应为 第一个序列的损失应为第二个序列的两倍，而第三个序列的损失应为零。\n",
    "loss = MaskedSoftmaxCELoss()\n",
    "loss(torch.ones(3, 4, 10), torch.ones((3, 4), dtype=torch.long),\n",
    "     torch.tensor([4, 2, 0]))"
   ],
   "id": "65239ee5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3026, 1.1513, 0.0000])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "origin_pos": 49
   },
   "cell_type": "markdown",
   "source": [
    "## Teacher Forcing\n",
    "\n",
    "**Teacher Forcing** 是一种在序列到序列（Sequence-to-Sequence）模型（如机器翻译、文本生成等）训练过程中常用的技术。其核心思想是：\n",
    "\n",
    "> 在解码器的训练过程中，使用目标序列的真实值（即目标词）作为解码器每一步的输入，而不是依赖模型自身在前一步生成的预测值。\n",
    "\n",
    "---\n",
    "\n",
    "### 工作原理\n",
    "\n",
    "1. **编码器阶段**：\n",
    "   - 编码器接收输入序列（如源语言句子），生成上下文向量（Context Vector）或隐藏状态。\n",
    "\n",
    "2. **解码器阶段（使用 Teacher Forcing）**：\n",
    "   - 在解码器的每个时间步：\n",
    "     - **输入**：目标序列的真实值（即 Ground Truth）。\n",
    "     - **输出**：预测的概率分布，用于计算损失。\n",
    "\n",
    "3. **损失计算**：\n",
    "   - 使用解码器的预测值与目标序列的真实值计算损失（如交叉熵损失），并进行反向传播优化模型。\n",
    "\n",
    "---\n",
    "\n",
    "### 优势\n",
    "\n",
    "1. **加速模型训练**：\n",
    "   - 使用目标序列的真实值作为输入，避免了模型错误的累积，从而使训练过程更加稳定。\n",
    "\n",
    "2. **提高收敛效率**：\n",
    "   - 模型可以更快地学习到目标序列的对齐关系和特征。\n",
    "\n",
    "---\n",
    "\n",
    "### 局限性\n",
    "\n",
    "1. **测试阶段的输入差异**：\n",
    "   - 在测试阶段，解码器只能依赖前一步生成的值作为下一步的输入，而不是目标序列的真实值。这种训练与测试阶段输入方式的不一致可能会导致模型性能下降。\n",
    "\n",
    "2. **模型过于依赖真实值**：\n",
    "   - 如果模型过于依赖真实值，可能会导致在测试阶段对错误的输入更敏感，从而影响生成质量。"
   ],
   "id": "6bdc4e96"
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:34.077404Z",
     "iopub.status.busy": "2023-08-18T07:15:34.076756Z",
     "iopub.status.idle": "2023-08-18T07:15:34.087405Z",
     "shell.execute_reply": "2023-08-18T07:15:34.086461Z"
    },
    "origin_pos": 51,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2025-04-09T03:10:35.473158Z",
     "start_time": "2025-04-09T03:10:35.457008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "# 修改了代码中的绘图方法\n",
    "# tgt_vocab: 目标词汇表，包含特殊标记（如 <bos>）。\n",
    "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n",
    "    def xavier_init_weights(m):\n",
    "        # 对 nn.Linear 层的权重使用 Xavier 均匀分布初始化。\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        if type(m) == nn.GRU:\n",
    "            # 对GRU使用 Xavier 初始化\n",
    "            for param in m._flat_weights_names:\n",
    "                if \"weight\" in param:\n",
    "                    nn.init.xavier_uniform_(m._parameters[param])\n",
    "\n",
    "    net.apply(xavier_init_weights)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    loss = MaskedSoftmaxCELoss()\n",
    "    net.train()\n",
    "\n",
    "    # 初始化 matplotlib 绘图\n",
    "    epochs = list(range(1, num_epochs + 1))\n",
    "    losses = []\n",
    "\n",
    "    # 开始训练\n",
    "    for epoch in range(num_epochs):\n",
    "        timer = d2l.Timer()\n",
    "        metric = d2l.Accumulator(2)  # 训练损失总和，词元数量\n",
    "        for batch in data_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
    "            bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0],\n",
    "                               device=device).reshape(-1, 1)\n",
    "            dec_input = torch.cat([bos, Y[:, :-1]], 1)\n",
    "            Y_hat, _ = net(X, dec_input, X_valid_len)\n",
    "            l = loss(Y_hat, Y, Y_valid_len)\n",
    "            l.sum().backward()\n",
    "            d2l.grad_clipping(net, 1)\n",
    "            num_tokens = Y_valid_len.sum()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l.sum(), num_tokens)\n",
    "\n",
    "        # 记录每轮的平均损失\n",
    "        avg_loss = metric[0] / metric[1]\n",
    "        losses.append(avg_loss)\n",
    "\n",
    "    # 绘制损失曲线\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(epochs, losses, label='Loss', color='blue')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Curve')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print(f'Final loss {losses[-1]:.3f}, {metric[1] / timer.stop():.1f} tokens/sec on {str(device)}')"
   ],
   "id": "9d7b922e",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Xavier 初始化？\n",
    "\n",
    "**Xavier 初始化** 是一种权重初始化方法，用于帮助神经网络的训练更快地收敛，并避免梯度消失或梯度爆炸问题。\n",
    "---\n",
    "### 核心思想\n",
    "\n",
    "Xavier 初始化的目标是让**每一层的输入和输出的方差相同**，从而保持信号的稳定传播。\n",
    "权重被初始化为一个均匀分布或正态分布，其标准差由神经元的输入和输出节点数量决定。\n",
    "\n",
    "#### 公式\n",
    "\n",
    "1. **均匀分布**：\n",
    "   $$\n",
    "   W \\sim U\\left(-\\sqrt{\\frac{6}{n_{\\text{in}} + n_{\\text{out}}}}, \\sqrt{\\frac{6}{n_{\\text{in}} + n_{\\text{out}}}}\\right)\n",
    "   $$\n",
    "\n",
    "2. **正态分布**：\n",
    "   $$\n",
    "   W \\sim N\\left(0, \\frac{2}{n_{\\text{in}} + n_{\\text{out}}}\\right)\n",
    "   $$\n",
    "\n",
    "- \\( n_{\\text{in}} \\): 当前层的输入神经元个数。\n",
    "- \\( n_{\\text{out}} \\): 当前层的输出神经元个数。\n",
    "\n",
    "---\n",
    "\n",
    "### 为什么需要 Xavier 初始化？\n",
    "\n",
    "在深度学习中，**权重初始化不当**可能会导致以下问题：\n",
    "1. **梯度消失**：如果权重太小，经过多层传播后，信号会逐渐衰减，导致梯度变得非常小，训练几乎停滞。\n",
    "2. **梯度爆炸**：如果权重太大，信号会在层与层之间逐渐放大，导致梯度过大，训练不稳定甚至发散。\n",
    "\n",
    "Xavier 初始化通过平衡输入和输出的方差，减少了这些问题的发生。\n"
   ],
   "id": "483d589ef16660ab"
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:34.091791Z",
     "iopub.status.busy": "2023-08-18T07:15:34.090975Z",
     "iopub.status.idle": "2023-08-18T07:16:11.767145Z",
     "shell.execute_reply": "2023-08-18T07:16:11.765998Z"
    },
    "origin_pos": 55,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2025-04-09T03:10:46.512417Z",
     "start_time": "2025-04-09T03:10:39.444033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1\n",
    "batch_size, num_steps = 64, 10\n",
    "lr, num_epochs, device = 0.005, 300, d2l.try_gpu()\n",
    "\n",
    "train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)\n",
    "encoder = Seq2SeqEncoder(len(src_vocab), embed_size, num_hiddens, num_layers,\n",
    "                        dropout)\n",
    "decoder = Seq2SeqDecoder(len(tgt_vocab), embed_size, num_hiddens, num_layers,\n",
    "                        dropout)\n",
    "net = d2l.EncoderDecoder(encoder, decoder)\n",
    "train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)"
   ],
   "id": "79f585d6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss 0.018, 44500.1 tokens/sec on cuda:0\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:16:11.771151Z",
     "iopub.status.busy": "2023-08-18T07:16:11.770496Z",
     "iopub.status.idle": "2023-08-18T07:16:11.779631Z",
     "shell.execute_reply": "2023-08-18T07:16:11.778678Z"
    },
    "origin_pos": 58,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2025-04-09T03:02:51.267510Z",
     "start_time": "2025-04-09T03:02:51.257547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 预测\n",
    "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,\n",
    "                    device, save_attention_weights=False):\n",
    "    # 在预测时将net设置为评估模式\n",
    "    net.eval()\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [\n",
    "        src_vocab['<eos>']]\n",
    "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
    "    src_tokens = d2l.truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "    # 添加批量轴\n",
    "    enc_X = torch.unsqueeze(\n",
    "        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
    "    enc_outputs = net.encoder(enc_X, enc_valid_len)\n",
    "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n",
    "    # 添加批量轴\n",
    "    dec_X = torch.unsqueeze(torch.tensor(\n",
    "        [tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)\n",
    "    output_seq, attention_weight_seq = [], []\n",
    "    for _ in range(num_steps):\n",
    "        Y, dec_state = net.decoder(dec_X, dec_state)\n",
    "        # 我们使用具有预测最高可能性的词元，作为解码器在下一时间步的输入\n",
    "        dec_X = Y.argmax(dim=2)\n",
    "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
    "        # 保存注意力权重（稍后讨论）\n",
    "        if save_attention_weights:\n",
    "            attention_weight_seq.append(net.decoder.attention_weights)\n",
    "        # 一旦序列结束词元被预测，输出序列的生成就完成了\n",
    "        if pred == tgt_vocab['<eos>']:\n",
    "            break\n",
    "        output_seq.append(pred)\n",
    "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq"
   ],
   "id": "7510bee7",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "origin_pos": 61
   },
   "cell_type": "markdown",
   "source": [
    "## 预测序列的评估\n",
    "\n",
    "我们可以通过与真实的标签序列进行比较来评估预测序列。\n",
    "虽然 :cite:`Papineni.Roukos.Ward.ea.2002`\n",
    "提出的BLEU（bilingual evaluation understudy）\n",
    "最先是用于评估机器翻译的结果，\n",
    "但现在它已经被广泛用于测量许多应用的输出序列的质量。\n",
    "原则上说，对于预测序列中的任意$n$元语法（n-grams），\n",
    "BLEU的评估都是这个$n$元语法是否出现在标签序列中。\n",
    "\n",
    "我们将BLEU定义为：\n",
    "\n",
    "$$ \\exp\\left(\\min\\left(0, 1 - \\frac{\\mathrm{len}_{\\text{label}}}{\\mathrm{len}_{\\text{pred}}}\\right)\\right) \\prod_{n=1}^k p_n^{1/2^n},$$\n",
    ":eqlabel:`eq_bleu`\n",
    "\n",
    "其中$\\mathrm{len}_{\\text{label}}$表示标签序列中的词元数和\n",
    "$\\mathrm{len}_{\\text{pred}}$表示预测序列中的词元数，\n",
    "$k$是用于匹配的最长的$n$元语法。\n",
    "另外，用$p_n$表示$n$元语法的精确度，它是两个数量的比值：\n",
    "第一个是预测序列与标签序列中匹配的$n$元语法的数量，\n",
    "第二个是预测序列中$n$元语法的数量的比率。\n",
    "具体地说，给定标签序列$A$、$B$、$C$、$D$、$E$、$F$\n",
    "和预测序列$A$、$B$、$B$、$C$、$D$，\n",
    "我们有$p_1 = 4/5$、$p_2 = 3/4$、$p_3 = 1/3$和$p_4 = 0$。\n",
    "\n",
    "根据 :eqref:`eq_bleu`中BLEU的定义，\n",
    "当预测序列与标签序列完全相同时，BLEU为$1$。\n",
    "此外，由于$n$元语法越长则匹配难度越大，\n",
    "所以BLEU为更长的$n$元语法的精确度分配更大的权重。\n",
    "具体来说，当$p_n$固定时，$p_n^{1/2^n}$\n",
    "会随着$n$的增长而增加（原始论文使用$p_n^{1/n}$）。\n",
    "而且，由于预测的序列越短获得的$p_n$值越高，\n",
    "所以 :eqref:`eq_bleu`中乘法项之前的系数用于惩罚较短的预测序列。\n",
    "例如，当$k=2$时，给定标签序列$A$、$B$、$C$、$D$、$E$、$F$\n",
    "和预测序列$A$、$B$，尽管$p_1 = p_2 = 1$，\n",
    "惩罚因子$\\exp(1-6/2) \\approx 0.14$会降低BLEU。\n",
    "\n",
    "[**BLEU的代码实现**]如下。\n"
   ],
   "id": "71773ad1"
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:16:11.784109Z",
     "iopub.status.busy": "2023-08-18T07:16:11.783827Z",
     "iopub.status.idle": "2023-08-18T07:16:11.791568Z",
     "shell.execute_reply": "2023-08-18T07:16:11.790396Z"
    },
    "origin_pos": 62,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2025-04-09T03:02:54.847764Z",
     "start_time": "2025-04-09T03:02:54.839693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def bleu(pred_seq, label_seq, k):  #@save\n",
    "    \"\"\"计算BLEU\"\"\"\n",
    "    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\n",
    "    len_pred, len_label = len(pred_tokens), len(label_tokens)\n",
    "    score = math.exp(min(0, 1 - len_label / len_pred))\n",
    "    for n in range(1, k + 1):\n",
    "        num_matches, label_subs = 0, collections.defaultdict(int)\n",
    "        for i in range(len_label - n + 1):\n",
    "            label_subs[' '.join(label_tokens[i: i + n])] += 1\n",
    "        for i in range(len_pred - n + 1):\n",
    "            if label_subs[' '.join(pred_tokens[i: i + n])] > 0:\n",
    "                num_matches += 1\n",
    "                label_subs[' '.join(pred_tokens[i: i + n])] -= 1\n",
    "        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n",
    "    return score"
   ],
   "id": "9135ade0",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "origin_pos": 63
   },
   "cell_type": "markdown",
   "source": [
    "最后，利用训练好的循环神经网络“编码器－解码器”模型，\n",
    "[**将几个英语句子翻译成法语**]，并计算BLEU的最终结果。\n"
   ],
   "id": "16c57898"
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:16:11.796025Z",
     "iopub.status.busy": "2023-08-18T07:16:11.795107Z",
     "iopub.status.idle": "2023-08-18T07:16:11.818936Z",
     "shell.execute_reply": "2023-08-18T07:16:11.817788Z"
    },
    "origin_pos": 64,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2025-04-09T03:02:56.914067Z",
     "start_time": "2025-04-09T03:02:56.888333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
    "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
    "for eng, fra in zip(engs, fras):\n",
    "    translation, attention_weight_seq = predict_seq2seq(\n",
    "        net, eng, src_vocab, tgt_vocab, num_steps, device)\n",
    "    print(f'{eng} => {translation}, bleu {bleu(translation, fra, k=2):.3f}')"
   ],
   "id": "653f0dd4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go . => va <unk> ., bleu 0.000\n",
      "i lost . => j'ai <unk> <unk> ?, bleu 0.000\n",
      "he's calm . => il est doucement ., bleu 0.658\n",
      "i'm home . => je suis calme ., bleu 0.512\n"
     ]
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "required_libs": [],
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
